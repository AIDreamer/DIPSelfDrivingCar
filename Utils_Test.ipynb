{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(12, 224, 224, 3)\n",
      "(12, 224, 224, 64)\n",
      "(12, 224, 224, 64)\n",
      "(12, 112, 112, 32)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test stacking with labels and some convolutions.\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import utils\n",
    "import tensorflow as tf\n",
    "from config import cfg\n",
    "import conv_bodies\n",
    "import modeling\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "\n",
    "model, weights_file, start_iter, checkpoints, output_dir = modeling.create_model()\n",
    "model.set_dataset('train_data/', 'train_labels/')\n",
    "\n",
    "\n",
    "init = (tf.global_variables_initializer(), \n",
    "        tf.local_variables_initializer(), \n",
    "        model.dataset[1].make_initializer(model.dataset[0]))\n",
    "\n",
    "model.tensor, model.labels = utils.stack_batch_into_tensor(model.dataset[0], train=True) # Normally use model.train\n",
    "\n",
    "print(type(model.tensor))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    with tf.variable_scope('conv1', reuse=tf.AUTO_REUSE):\n",
    "        print(model.tensor.shape)\n",
    "        model.Conv(3, 3, 64, padding='SAME', strides=[1,1,1,1])\n",
    "        print(model.tensor.shape)\n",
    "        model.Relu()\n",
    "    with tf.variable_scope('conv2', reuse=tf.AUTO_REUSE):\n",
    "        model.Conv(3, 64, 64, padding='SAME', strides=[1,1,1,1])\n",
    "        print(model.tensor.shape)\n",
    "        model.Relu()\n",
    "        # Strides[0] must be 1, else\n",
    "        # UnimplementError Pooling is not yet supported on the batch dimension\n",
    "        model.MaxPool(ksize=[1,1,2,1], strides=[1,2,2,2], padding='SAME')\n",
    "        print(model.tensor.shape)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "End of training dataset.\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(2, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test loading datasets and iterating on them.\n",
    "\"\"\"\n",
    "\n",
    "dataset, iterator = utils.load_dataset('train_data/', 'train_labels/')\n",
    "tensor = iterator.get_next()\n",
    "next_element = iterator.get_next()\n",
    "init = iterator.make_initializer(dataset)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Initialize the iterator on the training data\n",
    "    sess.run(init)\n",
    "    tensor = sess.run(tensor)[0]\n",
    "    print(type(tensor))\n",
    "    # get each element of the training dataset until the end is reached\n",
    "    while True:\n",
    "        try:\n",
    "            elem = sess.run(next_element)\n",
    "            tensor = tf.stack((tensor, elem[0]), axis=0)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of training dataset.\")\n",
    "            print(type(tensor))\n",
    "            print(tensor.shape)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test stacking without labels and a convolutions.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import utils\n",
    "import tensorflow as tf\n",
    "from config import cfg\n",
    "import conv_bodies\n",
    "import modeling\n",
    "    \n",
    "\n",
    "model, weights_file, start_iter, checkpoints, output_dir = modeling.create_model()\n",
    "model.set_dataset('train_data/')\n",
    "\n",
    "\n",
    "init = (tf.global_variables_initializer(), \n",
    "            tf.local_variables_initializer(), \n",
    "            model.dataset[1].make_initializer(model.dataset[0]))\n",
    "\n",
    "model.tensor = utils.stack_batch_into_tensor(model.dataset[0], train=False) # Normally use model.train\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    with tf.variable_scope('conv', reuse=tf.AUTO_REUSE):\n",
    "        model.Conv(3, 3, 64, padding='SAME', strides=[1,1,1,1])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

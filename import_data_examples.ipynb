{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[[ 35,  34,  32],\n",
      "        [ 38,  37,  35],\n",
      "        [ 27,  26,  24],\n",
      "        ...,\n",
      "        [166, 188, 209],\n",
      "        [166, 188, 211],\n",
      "        [166, 188, 211]],\n",
      "\n",
      "       [[ 49,  49,  49],\n",
      "        [ 46,  46,  44],\n",
      "        [ 31,  31,  31],\n",
      "        ...,\n",
      "        [166, 188, 209],\n",
      "        [166, 188, 211],\n",
      "        [166, 188, 211]],\n",
      "\n",
      "       [[ 61,  62,  64],\n",
      "        [ 52,  54,  53],\n",
      "        [ 39,  40,  42],\n",
      "        ...,\n",
      "        [166, 188, 209],\n",
      "        [166, 188, 211],\n",
      "        [166, 188, 211]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  2,   7,   1],\n",
      "        [  2,   7,   1],\n",
      "        [  2,   7,   1],\n",
      "        ...,\n",
      "        [  5,   6,   1],\n",
      "        [  6,   7,   2],\n",
      "        [  7,   8,   3]],\n",
      "\n",
      "       [[  4,   9,   3],\n",
      "        [  4,   9,   3],\n",
      "        [  4,   9,   3],\n",
      "        ...,\n",
      "        [  5,   6,   1],\n",
      "        [  6,   7,   2],\n",
      "        [  7,   8,   3]],\n",
      "\n",
      "       [[  5,  10,   4],\n",
      "        [  5,  10,   4],\n",
      "        [  6,  11,   5],\n",
      "        ...,\n",
      "        [  5,   6,   1],\n",
      "        [  6,   7,   2],\n",
      "        [  6,   7,   2]]], dtype=uint8), array([[[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [ 90, 116,  21],\n",
      "        [ 90, 116,  21],\n",
      "        [ 90, 116,  21]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]],\n",
      "\n",
      "       [[  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        ...,\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0],\n",
      "        [  0,   0,   0]]], dtype=uint8))\n",
      "(array([[[ 80,  91,  51],\n",
      "        [ 78,  89,  49],\n",
      "        [ 75,  85,  48],\n",
      "        ...,\n",
      "        [247, 253, 253],\n",
      "        [247, 253, 253],\n",
      "        [247, 253, 253]],\n",
      "\n",
      "       [[ 89, 100,  60],\n",
      "        [ 82,  93,  53],\n",
      "        [ 74,  84,  47],\n",
      "        ...,\n",
      "        [248, 254, 254],\n",
      "        [248, 254, 254],\n",
      "        [248, 254, 254]],\n",
      "\n",
      "       [[ 80,  91,  51],\n",
      "        [ 79,  90,  50],\n",
      "        [ 81,  91,  54],\n",
      "        ...,\n",
      "        [248, 254, 254],\n",
      "        [248, 254, 254],\n",
      "        [248, 254, 254]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 29,  47,  23],\n",
      "        [ 26,  46,  21],\n",
      "        [ 30,  50,  23],\n",
      "        ...,\n",
      "        [ 40,  78,   3],\n",
      "        [ 21,  57,   0],\n",
      "        [ 48,  84,  10]],\n",
      "\n",
      "       [[ 30,  50,  25],\n",
      "        [ 32,  55,  29],\n",
      "        [ 30,  53,  25],\n",
      "        ...,\n",
      "        [ 66, 104,  31],\n",
      "        [ 36,  72,   0],\n",
      "        [ 47,  80,   9]],\n",
      "\n",
      "       [[ 44,  67,  41],\n",
      "        [ 33,  56,  30],\n",
      "        [ 11,  36,   7],\n",
      "        ...,\n",
      "        [ 49,  87,  14],\n",
      "        [ 24,  57,   0],\n",
      "        [ 33,  66,   0]]], dtype=uint8), array([[[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]], dtype=uint8))\n",
      "End of training dataset.\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------- #\n",
    "# Method 1 - Input pipeline with Dataset\n",
    "# ---------------------------------------------------------------------------- #\n",
    "# https://www.tensorflow.org/programmers_guide/datasets\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\"\"\"\n",
    "In the examle code at the above URL, they have a line in their _parse_function:\n",
    "image_resized = tf.image.resize_images(image_decoded, [28, 28])\n",
    "This throws an error because decode_image() returns a variable without shape\n",
    "because gifs have a 4 dimensions (animation) instead of three. To resize images,\n",
    "use the specific decode_jpeg() and decode_png() methods. \n",
    "\"\"\"\n",
    "def _parse_function(data_file, label_file):\n",
    "    data_string = tf.read_file(data_file)\n",
    "    label_string = tf.read_file(label_file)\n",
    "    data = tf.image.decode_image(data_string)\n",
    "    label = tf.image.decode_image(label_string)\n",
    "    return data, label\n",
    "    \n",
    "\"\"\"\n",
    "Getting filenames of data -\n",
    "There are two ways of doing this, both are below. The first wat creates a \n",
    "constant tensor by manually hardcoding in the names of every data file. This is \n",
    "not scalable of flexible (it's possible to use os.listdir, but this is messy). \n",
    "The second way is to use tf.train.match_filenames_once. This is the way to go.\n",
    "In the documentation for this at:\n",
    "https://www.tensorflow.org/versions/r1.1/api_docs/python/tf/train/match_filenames_once\n",
    "it says it returns a variable initialized to the list of filenames, but if you\n",
    "run this through the rest of the code you'll get the error:\n",
    "FailedPreconditionError: Attempting to use uninitialized value matching_filenames_9\n",
    "or some other matching filename. The solution to this is to use the\n",
    "initialized_value() method for Variables, which I guess initalized each item in \n",
    "the list the variable is initialized to. \n",
    "https://stackoverflow.com/questions/36007883/tensorflow-attempting-to-use-uninitialized-value-in-variable-initialization\n",
    "\"\"\"\n",
    "# Get data\n",
    "# train_imgs = tf.constant(['train_data/ADE_train_00012440.jpg', \n",
    "#                           'train_data/ADE_train_00012557.jpg'])\n",
    "\n",
    "train_data_filenames = tf.train.match_filenames_once('train_data/*.jpg').initialized_value()\n",
    "\n",
    "# train_labels = tf.constant(['train_labels/ADE_train_00012440_seg.png', \n",
    "#                             'train_labels/ADE_train_00012557_seg.png'])\n",
    "\n",
    "train_labels_filenames = tf.train.match_filenames_once('train_labels/*.png').initialized_value()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Creating TensorFlow Dataset object -\n",
    "Use the from_tensor_slices() method as shown below. As the documentation \n",
    "describes at:\n",
    "https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices\n",
    "if the agrument is a nested tuple of tensors, the tensors must all have the \n",
    "same size in the zero dimension. Each element of the dataset will have the same \n",
    "nested structure as the argument, but instead of tensors as elements it will have\n",
    "the element of each tensor in the argument, at the index of the element in the\n",
    "dataset. For example, if we had\n",
    "tf.data.Dataset.from_tensor_slices((tensor1, tensor2))\n",
    "then the first element would be\n",
    "(tensor1[0], tensor2[0])\n",
    "the second element would be\n",
    "(thesor1[1], tensor2[1])\n",
    "and so on.\n",
    "\n",
    "The map() method for Dataset objects takes in a function, performs that\n",
    "function on each element in the dataset, and then returns the transformed \n",
    "dataset. For our purposes, we want to transform our dataset of filenames into\n",
    "a dataset of decoded image files. \n",
    "\"\"\"\n",
    "# Create dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data_filenames, \n",
    "                                              train_labels_filenames))\n",
    "train_dataset = train_dataset.map(_parse_function)\n",
    "\n",
    "\"\"\"\n",
    "Create TensorFlow Iterator object -\n",
    "There are two ways to do this, both shown below. There isn't a big difference\n",
    "between the two of them. I think the better way is to keep with the Dataset \n",
    "class method to do it, but under the hood I'm pretty sure it's the same as the \n",
    "first method.\n",
    "\"\"\"\n",
    "# Create iterator\n",
    "# iterator = tf.data.Iterator.from_structure(train_dataset.output_types, \n",
    "#                                            train_dataset.output_shapes)\n",
    "iterator = train_dataset.make_initializable_iterator()\n",
    "\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Initialize stuff -\n",
    "Normally it's necessary to initialize global and local variables, but in this\n",
    "example it's not. All that needs to be initialized is the iterator.\n",
    "\"\"\"\n",
    "# Initialize stuff\n",
    "# init = (tf.global_variables_initializer(), \n",
    "#         tf.local_variables_initializer(), \n",
    "#         iterator.make_initializer(train_dataset))\n",
    "\n",
    "init = iterator.make_initializer(train_dataset)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Initialize the iterator on the training data\n",
    "    sess.run(init)\n",
    "\n",
    "    # get each element of the training dataset until the end is reached\n",
    "    while True:\n",
    "        try:\n",
    "            elem = sess.run(next_element)\n",
    "            print(elem)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of training dataset.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[ 80,  91,  51],\n",
      "        [ 78,  89,  49],\n",
      "        [ 75,  85,  48],\n",
      "        ...,\n",
      "        [247, 253, 253],\n",
      "        [247, 253, 253],\n",
      "        [247, 253, 253]],\n",
      "\n",
      "       [[ 89, 100,  60],\n",
      "        [ 82,  93,  53],\n",
      "        [ 74,  84,  47],\n",
      "        ...,\n",
      "        [248, 254, 254],\n",
      "        [248, 254, 254],\n",
      "        [248, 254, 254]],\n",
      "\n",
      "       [[ 80,  91,  51],\n",
      "        [ 79,  90,  50],\n",
      "        [ 81,  91,  54],\n",
      "        ...,\n",
      "        [248, 254, 254],\n",
      "        [248, 254, 254],\n",
      "        [248, 254, 254]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 29,  47,  23],\n",
      "        [ 26,  46,  21],\n",
      "        [ 30,  50,  23],\n",
      "        ...,\n",
      "        [ 40,  78,   3],\n",
      "        [ 21,  57,   0],\n",
      "        [ 48,  84,  10]],\n",
      "\n",
      "       [[ 30,  50,  25],\n",
      "        [ 32,  55,  29],\n",
      "        [ 30,  53,  25],\n",
      "        ...,\n",
      "        [ 66, 104,  31],\n",
      "        [ 36,  72,   0],\n",
      "        [ 47,  80,   9]],\n",
      "\n",
      "       [[ 44,  67,  41],\n",
      "        [ 33,  56,  30],\n",
      "        [ 11,  36,   7],\n",
      "        ...,\n",
      "        [ 49,  87,  14],\n",
      "        [ 24,  57,   0],\n",
      "        [ 33,  66,   0]]], dtype=uint8)]\n",
      "[array([[[ 35,  34,  32],\n",
      "        [ 38,  37,  35],\n",
      "        [ 27,  26,  24],\n",
      "        ...,\n",
      "        [166, 188, 209],\n",
      "        [166, 188, 211],\n",
      "        [166, 188, 211]],\n",
      "\n",
      "       [[ 49,  49,  49],\n",
      "        [ 46,  46,  44],\n",
      "        [ 31,  31,  31],\n",
      "        ...,\n",
      "        [166, 188, 209],\n",
      "        [166, 188, 211],\n",
      "        [166, 188, 211]],\n",
      "\n",
      "       [[ 61,  62,  64],\n",
      "        [ 52,  54,  53],\n",
      "        [ 39,  40,  42],\n",
      "        ...,\n",
      "        [166, 188, 209],\n",
      "        [166, 188, 211],\n",
      "        [166, 188, 211]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  2,   7,   1],\n",
      "        [  2,   7,   1],\n",
      "        [  2,   7,   1],\n",
      "        ...,\n",
      "        [  5,   6,   1],\n",
      "        [  6,   7,   2],\n",
      "        [  7,   8,   3]],\n",
      "\n",
      "       [[  4,   9,   3],\n",
      "        [  4,   9,   3],\n",
      "        [  4,   9,   3],\n",
      "        ...,\n",
      "        [  5,   6,   1],\n",
      "        [  6,   7,   2],\n",
      "        [  7,   8,   3]],\n",
      "\n",
      "       [[  5,  10,   4],\n",
      "        [  5,  10,   4],\n",
      "        [  6,  11,   5],\n",
      "        ...,\n",
      "        [  5,   6,   1],\n",
      "        [  6,   7,   2],\n",
      "        [  6,   7,   2]]], dtype=uint8)]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------------------- #\n",
    "# Method 2 - Input pipeline with Queue\n",
    "# ---------------------------------------------------------------------------- #\n",
    "# https://gist.github.com/eerwitt/518b0c9564e500b4b50f\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\"\"\"\n",
    "See Method 1 for documentation on getting filenames\n",
    "\"\"\"\n",
    "# filenames = tf.constant(['train_data/ADE_train_00012440.jpg', \n",
    "#                           'train_data/ADE_train_00012557.jpg'])\n",
    "\n",
    "filenames = tf.train.match_filenames_once('train_data/*.jpg')\n",
    "\n",
    "# Create a TensorFlow queue from the list of filenames\n",
    "filename_queue = tf.train.string_input_producer(filenames)\n",
    "\n",
    "\"\"\"\n",
    "Create a TensorFlow WholeFileReader object -\n",
    "The read() method  reads the next file from the quueue and returns a tuple. \n",
    "The first element is the filename or 'key', the second element is the string \n",
    "of file data or 'value'. For our purposes we don't care about the filename and \n",
    "focus on the data. \n",
    "\n",
    "The decode_image() method takes a string of file data as a argument and decodes it\n",
    "into a Dense Tensor based on it's format. There are decode_jpeg() and decode_png() \n",
    "methods as well as specific methods for other image formats. The decode_image() method \n",
    "is a convience method that will detect the image format and properly decode it. \n",
    "\n",
    "\"\"\"\n",
    "# Create reader\n",
    "image_reader = tf.WholeFileReader()\n",
    "\n",
    "# Read file from queue (we don't use the filename returned)\n",
    "filename, image_file = image_reader.read(filename_queue)\n",
    "\n",
    "# Decode image into Dense Tensor\n",
    "image = tf.image.decode_image(image_file)\n",
    "\n",
    "\"\"\"\n",
    "Initialize stuff - \n",
    "Here we actually do need to initialize both global and local variables\n",
    "\"\"\"\n",
    "# Initialize stuff\n",
    "init = (tf.global_variables_initializer(),\n",
    "        tf.local_variables_initializer())\n",
    "\n",
    "# Start a new session to show example output.\n",
    "with tf.Session() as sess:\n",
    "    # Ititialize global and local variables\n",
    "    sess.run(init)\n",
    "\n",
    "    # Coordinate the loading of image files.\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "    # Get the first image tensor from the queue and print its value.\n",
    "    image_tensor = sess.run([image])\n",
    "    print(image_tensor)\n",
    "    # Get the second image tensor from the queue and print its value.\n",
    "    image_tensor = sess.run([image])\n",
    "    print(image_tensor)\n",
    "\n",
    "    # Stop the filename queue coordinator.\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'matching_filenames_1:0' shape=<unknown> dtype=string_ref>\n",
      "Tensor(\"Const_2:0\", shape=(2,), dtype=string)\n",
      "[b'train_data/ADE_train_00012440.jpg' b'train_data/ADE_train_00012557.jpg']\n",
      "[b'train_data/ADE_train_00012440.jpg' b'train_data/ADE_train_00012557.jpg']\n"
     ]
    }
   ],
   "source": [
    "filenames_match = tf.train.match_filenames_once('train_data/*.jpg')\n",
    "filenames_const = tf.constant(['train_data/ADE_train_00012440.jpg', \n",
    "                               'train_data/ADE_train_00012557.jpg'])\n",
    "\n",
    "init = (tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "print(filenames_match)\n",
    "print(filenames_const)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(filenames_match))\n",
    "    print(sess.run(filenames_const))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
